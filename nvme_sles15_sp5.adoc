---
sidebar: sidebar 
permalink: nvme_sles15_sp5.html 
keywords: nvme, linux, suse, sles, 15, SP5, server, enterprise 
summary: ONTAP를 사용하여 SUSE Linux Enterprise Server 15 SP5용 NVMe/FC를 구성하는 방법을 설명합니다 
---
= ONTAP를 사용하는 SUSE Linux Enterprise Server 15 SP5용 NVMe-oF 호스트 구성
:toc: macro
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toc: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:toc-position: content


[role="lead"]
NVMe/FC(NVMe over Fibre Channel) 및 기타 전송을 포함한 NVMe-oF(NVMe over Fabrics)는 SUSE Linux Enterprise Server(SLES) 15 SP5와 ANA(Asymmetric Namespace Access)가 지원됩니다. NVMe-oF 환경에서 ANA는 iSCSI 및 FCP 환경에서 ALUA 다중 경로와 이와 같으며 커널 내 NVMe 다중 경로를 통해 구현됩니다.

ONTAP를 사용하는 SLES 15 SP5의 NVMe-oF 호스트 구성에 대해 다음과 같은 지원을 사용할 수 있습니다.

* NVMe와 SCSI 트래픽을 모두 동일한 동일한 호스트에서 실행할 수 있습니다. 따라서 SCSI LUN의 경우 SCSI mpath 장치에 대해 dm-multipath를 구성할 수 있지만 NVMe multipath를 사용하여 호스트에 NVMe-oF 네임스페이스 장치를 구성할 수 있습니다.
* NVMe/FC 외에 NVMe over TCP(NVMe/TCP) 지원 NetApp 플러그인은 기본 제공됩니다 `nvme-cli` 패키지에는 NVMe/FC 및 NVMe/TCP 네임스페이스에 대한 ONTAP 세부 정보가 표시됩니다.


지원되는 구성에 대한 자세한 내용은 를 참조하십시오 link:https://mysupport.netapp.com/matrix/["NetApp 상호 운용성 매트릭스 툴"^].



== 피처

* NVMe 보안 대역 내 인증 지원
* 고유한 검색 NQN을 사용하여 영구 검색 컨트롤러(PDC)를 지원합니다




== 알려진 제한 사항

* 현재 NVMe-oF 프로토콜을 사용한 SAN 부팅은 지원되지 않습니다.
* 그런 거 없어 `sanlun` NVMe-oF 지원 따라서 SLES 15 SP5 호스트에서 NVMe-oF에 대한 호스트 유틸리티 지원을 사용할 수 없습니다. 모든 NVMe-oF 전송에 대해 기본 NVMe-CLI 패키지에 포함된 NetApp 플러그인을 사용할 수 있습니다.




== NVMe/FC 구성

Broadcom/Emulex FC 또는 Marvell/Qlogic FC 어댑터에 대해 NVMe/FC를 구성할 수 있습니다.

[role="tabbed-block"]
====
.Broadcom/Emulex
--
.단계
. 권장 어댑터 모델을 사용하고 있는지 확인합니다.
+
[listing]
----
cat /sys/class/scsi_host/host*/modelname
----
+
* 출력 예 *:

+
[listing]
----
LPe32002 M2
LPe32002-M2
----
. 어댑터 모델 설명을 확인합니다.
+
[listing]
----
cat /sys/class/scsi_host/host*/modeldesc
----
+
* 출력 예 *:

+
[listing]
----
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. 권장되는 Emulex HBA(호스트 버스 어댑터) 펌웨어 버전을 사용하고 있는지 확인합니다.
+
[listing]
----
cat /sys/class/scsi_host/host*/fwrev
----
+
* 출력 예 *:

+
[listing]
----
14.0.639.20, sli-4:2:c
14.0.639.20, sli-4:2:c
----
. 권장되는 lpfc 드라이버 버전을 사용하고 있는지 확인합니다.
+
[listing]
----
cat /sys/module/lpfc/version
----
+
* 출력 예 *:

+
[listing]
----
0:14.2.0.13
----
. 이니시에이터 포트를 볼 수 있는지 확인합니다.
+
[listing]
----
cat /sys/class/fc_host/host*/port_name
----
+
* 출력 예 *:

+
[listing]
----
0x100000109b579d5e
0x100000109b579d5f

----
. 이니시에이터 포트가 온라인 상태인지 확인합니다.
+
[listing]
----
cat /sys/class/fc_host/host*/port_state
----
+
* 출력 예 *:

+
[listing]
----
Online
Online
----
. NVMe/FC 이니시에이터 포트가 활성화되었고 타겟 포트가 표시되는지 확인합니다.
+
[listing]
----
cat /sys/class/scsi_host/host*/nvme_info
----
+
* 출력 예 *:

+
이 예에서는 이니시에이터 포트 하나가 설정되고 두 개의 타겟 LIF로 연결됩니다.

+
[listing, subs="+quotes"]
----
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b579d5e WWNN x200000109b579d5e DID x011c00 *ONLINE*
NVME RPORT WWPN x208400a098dfdd91 WWNN x208100a098dfdd91 DID x011503
*TARGET DISCSRVC ONLINE*
NVME RPORT WWPN x208500a098dfdd91 WWNN x208100a098dfdd91 DID x010003
*TARGET DISCSRVC *ONLINE*

NVME Statistics
LS: Xmt 0000000e49 Cmpl 0000000e49 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000003ceb594f Issue 000000003ce65dbe OutIO fffffffffffb046f
abort 00000bd2 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr
00000000 err 00000000
FCP CMPL: xb 000014f4 Err 00012abd

NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b579d5f WWNN x200000109b579d5f DID x011b00 *ONLINE*
NVME RPORT WWPN x208300a098dfdd91 WWNN x208100a098dfdd91 DID x010c03
*TARGET DISCSRVC ONLINE*
NVME RPORT WWPN x208200a098dfdd91 WWNN x208100a098dfdd91 DID x012a03
*TARGET DISCSRVC ONLINE*

NVME Statistics
LS: Xmt 0000000e50 Cmpl 0000000e50 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000003c9859ca Issue 000000003c93515e OutIO fffffffffffaf794
abort 00000b73 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr
00000000 err 00000000
FCP CMPL: xb 0000159d Err 000135c3

----
. 호스트를 재부팅합니다.


--
.Marvell/QLogic
--
.단계
. SLES 15 SP5 커널에 포함된 기본 받은 편지함 qla2xxx 드라이버에는 ONTAP 지원에 필요한 최신 수정 사항이 포함되어 있습니다. 지원되는 어댑터 드라이버 및 펌웨어 버전을 실행하고 있는지 확인합니다.
+
[listing]
----
cat /sys/class/fc_host/host*/symbolic_name
----
+
* 출력 예 *:

+
[listing]
----
QLE2742 FW:v9.12.01 DVR: v10.02.08.300-k
QLE2742 FW:v9.12.01 DVR: v10.02.08.300-k

----
. 를 확인합니다 `ql2xnvmeenable` 매개 변수는 1로 설정됩니다.
+
[listing]
----
cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== 1MB I/O 크기 활성화(옵션)

ONTAP는 컨트롤러 식별 데이터에 8의 MDTS(MAX Data 전송 크기)를 보고합니다. 이는 최대 I/O 요청 크기가 1MB가 될 수 있음을 의미합니다. 그러나 Broadcom NVMe/FC 호스트에 대해 1MB의 입출력 요청을 발급하려면 을 늘려야 합니다 `lpfc` 의 값 `lpfc_sg_seg_cnt` 매개 변수를 기본값 64에서 256으로 설정합니다.

.단계
. lpfc_sg_seg_cnt 매개변수를 256으로 설정합니다.
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. dracut -f 명령을 실행하고 호스트를 재부팅합니다.
. lpfc_sg_seg_cnt가 256인지 확인합니다.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----



NOTE: Qlogic NVMe/FC 호스트에는 적용되지 않습니다.



=== NVMe 서비스 활성화

에는 2가지 NVMe/FC 부팅 서비스가 포함되어 있습니다 `nvme-cli` 그러나 패키지는 _ 만 _ 입니다 `nvmefc-boot-connections.service` 시스템 부팅 중에 시작하도록 설정되어 있습니다.  `nvmf-autoconnect.service` 이(가) 활성화되지 않았습니다. 따라서 수동으로 을 사용하도록 설정해야 합니다 `nvmf-autoconnect.service` 를 눌러 시스템을 부팅합니다.

.단계
. 활성화 `nvmf-autoconnect.service`:
+
[listing]
----
# systemctl enable nvmf-autoconnect.service
Created symlink /etc/systemd/system/default.target.wants/nvmf- autoconnect.service → /usr/lib/systemd/system/nvmf-autoconnect.service.

----
. 호스트를 재부팅합니다.
. 확인합니다 `nvmf-autoconnect.service` 및 `nvmefc-boot-connections.service` 시스템이 부팅된 후 실행 중인 경우:
+
* 출력 예: *

+
[listing]
----
# systemctl status nvmf-autoconnect.service
nvmf-autoconnect.service - Connect NVMe-oF subsystems automatically during boot
Loaded: loaded (/usr/lib/systemd/system/nvmf-autoconnect.service; enabled; vendor preset: disabled)
Active: inactive (dead) since Thu 2023-05-25 14:55:00 IST; 11min
ago
Process: 2108 ExecStartPre=/sbin/modprobe nvme-fabrics (code=exited,
status=0/SUCCESS)
Process: 2114 ExecStart=/usr/sbin/nvme connect-all (code=exited, status=0/SUCCESS)
Main PID: 2114 (code=exited, status=0/SUCCESS)

systemd[1]: Starting Connect NVMe-oF subsystems automatically during boot...
nvme[2114]: traddr=nn-0x201700a098fd4ca6:pn-0x201800a098fd4ca6 is already connected
systemd[1]: nvmf-autoconnect.service: Deactivated successfully. systemd[1]: Finished Connect NVMe-oF subsystems automatically during
boot.

# systemctl status nvmefc-boot-connections.service
nvmefc-boot-connections.service - Auto-connect to subsystems on FC-NVME devices found during boot
Loaded: loaded (/usr/lib/systemd/system/nvmefc-boot- connections.service; enabled; vendor preset: enabled)
Active: inactive (dead) since Thu 2023-05-25 14:55:00 IST; 11min ago Main PID: 1647 (code=exited, status=0/SUCCESS)

systemd[1]: Starting Auto-connect to subsystems on FC-NVME devices found during boot...
systemd[1]: nvmefc-boot-connections.service: Succeeded.
systemd[1]: Finished Auto-connect to subsystems on FC-NVME devices found during boot.

----




== NVMe/TCP를 구성합니다

다음 절차를 사용하여 NVMe/TCP를 구성할 수 있습니다.

.단계
. 이니시에이터 포트가 지원되는 NVMe/TCP LIF에서 검색 로그 페이지 데이터를 가져올 수 있는지 확인합니다.
+
[listing]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
* 출력 예 *:

+
[listing, subs="+quotes"]
----
# nvme discover -t tcp -w 192.168.1.4 -a 192.168.1.31

Discovery Log Number of Records 8, Generation counter 18
=====Discovery Log Entry 0====== trtype: tcp
adrfam: ipv4
subtype: *current discovery subsystem* treq: not specified
portid: 0
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.2.117
eflags: *explicit discovery connections, duplicate discovery information sectype: none*
=====Discovery Log Entry 1====== trtype: tcp
adrfam: ipv4
subtype: *current discovery subsystem* treq: not specified
portid: 1
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.1.117
eflags: *explicit discovery connections, duplicate discovery information sectype: none*
=====Discovery Log Entry 2====== trtype: tcp
adrfam: ipv4
subtype: *current discovery subsystem* treq: not specified
portid: 2
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.2.116
eflags: *explicit discovery connections, duplicate discovery information sectype: none*
=====Discovery Log Entry 3====== trtype: tcp
adrfam: ipv4
subtype: *current discovery subsystem* treq: not specified
portid: 3
trsvcid: 8009 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery traddr: 192.168.1.116
eflags: *explicit discovery connections, duplicate discovery information sectype: none*
=====Discovery Log Entry 4====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 0
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.2.117 eflags: not specified sectype: none
=====Discovery Log Entry 5====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 1
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.1.117 eflags: not specified sectype: none
=====Discovery Log Entry 6====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 2
trsvcid: 4420
subnqn: nqn.1992- 08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.2.116 eflags: not specified sectype: none
=====Discovery Log Entry 7====== trtype: tcp
adrfam: ipv4
subtype: nvme subsystem treq: not specified portid: 3
trsvcid: 4420 subnqn: nqn.1992-
08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIEN T116
traddr: 192.168.1.116 eflags: not specified sectype: none
----
. 다른 모든 NVMe/TCP 이니시에이터-타겟 LIF 조합이 검색 로그 페이지 데이터를 성공적으로 가져올 수 있는지 확인합니다.
+
[listing]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
* 출력 예: *

+
[listing]
----
# nvme discover -t tcp -w 192.168.1.4 -a 192.168.1.32
# nvme discover -t tcp -w 192.168.2.5 -a 192.168.2.36
# nvme discover -t tcp -w 192.168.2.5 -a 192.168.2.37
----
. 를 실행합니다 `nvme connect-all` 노드에 걸쳐 지원되는 모든 NVMe/TCP 이니시에이터-타겟 LIF에 대한 명령:
+
[listing]
----
nvme connect-all -t tcp -w host-traddr -a traddr -l <ctrl_loss_timeout_in_seconds>
----
+
* 출력 예: *

+
[listing]
----
# nvme connect-all -t tcp -w 192.168.1.4 -a 192.168.1.31 -l -1
# nvme connect-all -t tcp -w 192.168.1.4 -a 192.168.1.32 -l -1
# nvme connect-all -t tcp -w 192.168.2.5 -a 192.168.1.36 -l -1
# nvme connect-all -t tcp -w 192.168.2.5 -a 192.168.1.37 -l -1
----
+

NOTE: NetApp은 를 설정할 것을 권장합니다 `ctrl-loss-tmo` 옵션을 로 설정합니다 `-1` 따라서 경로 손실이 발생하면 NVMe/TCP 이니시에이터가 무한정 다시 연결을 시도합니다.





== NVMe-oF를 검증합니다

다음 절차를 사용하여 NVMe-oF를 검증할 수 있습니다.

.단계
. 커널 내 NVMe 다중 경로가 활성화되었는지 확인:
+
[listing]
----
cat /sys/module/nvme_core/parameters/multipath
Y
----
. 호스트에 ONTAP NVMe 네임스페이스에 대한 올바른 컨트롤러 모델이 있는지 확인합니다.
+
[listing]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/model
----
+
* 출력 예: *

+
[listing]
----
NetApp ONTAP Controller
NetApp ONTAP Controller
----
. 해당 ONTAP NVMe I/O 컨트롤러에 대한 NVMe I/O 정책을 확인합니다.
+
[listing]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
----
+
* 출력 예: *

+
[listing]
----
round-robin
round-robin
----
. ONTAP 네임스페이스가 호스트에 표시되는지 확인합니다.
+
[listing]
----
nvme list -v
----
+
* 출력 예: *

+
[listing]
----
Subsystem        Subsystem-NQN                                                                         Controllers
---------------- ------------------------------------------------------------------------------------ -----------------------
nvme-subsys0     nqn.1992- 08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_dhcha p	nvme0, nvme1, nvme2, nvme3


Device   SN                   MN                                       FR       TxPort Asdress        Subsystem    Namespaces
-------- -------------------- ---------------------------------------- -------- ---------------------------------------------
nvme0    81LGgBUqsI3EAAAAAAAE NetApp ONTAP Controller   FFFFFFFF tcp traddr=192.168.2.214,trsvcid=4420,host_traddr=192.168.2.14 nvme-subsys0 nvme0n1
nvme1    81LGgBUqsI3EAAAAAAAE NetApp ONTAP Controller   FFFFFFFF tcp traddr=192.168.2.215,trsvcid=4420,host_traddr=192.168.2.14 nvme-subsys0 nvme0n1
nvme2    81LGgBUqsI3EAAAAAAAE NetApp ONTAP Controller   FFFFFFFF tcp traddr=192.168.1.214,trsvcid=4420,host_traddr=192.168.1.14 nvme-subsys0 nvme0n1
nvme3    81LGgBUqsI3EAAAAAAAE NetApp ONTAP Controller   FFFFFFFF tcp traddr=192.168.1.215,trsvcid=4420,host_traddr=192.168.1.14 nvme-subsys0 nvme0n1


Device       Generic      NSID       Usage                 Format         Controllers
------------ ------------ ---------- -------------------------------------------------------------
/dev/nvme0n1 /dev/ng0n1   0x1     1.07  GB /   1.07  GB    4 KiB +  0 B   nvme0, nvme1, nvme2, nvme3

----
. 각 경로의 컨트롤러 상태가 라이브이고 올바른 ANA 상태인지 확인합니다.
+
[listing]
----
nvme list-subsys /dev/<subsystem_name>
----
+
[role="tabbed-block"]
====
.NVMe/FC
--
* 예제 출력 *

[listing, subs="+quotes"]
----
# nvme list-subsys /dev/nvme1n1
nvme-subsys1 - NQN=nqn.1992-08.com.netapp:sn.04ba0732530911ea8e8300a098dfdd91:subsystem.nvme_145_1
\
+- nvme2 *fc* traddr=nn-0x208100a098dfdd91:pn- 0x208200a098dfdd91,host_traddr=nn-0x200000109b579d5f:pn-0x100000109b579d5f *live optimized*
+- nvme3 *fc* traddr=nn-0x208100a098dfdd91:pn- 0x208500a098dfdd91,host_traddr=nn-0x200000109b579d5e:pn-0x100000109b579d5e *live optimized*
+- nvme4 *fc* traddr=nn-0x208100a098dfdd91:pn- 0x208400a098dfdd91,host_traddr=nn-0x200000109b579d5e:pn-0x100000109b579d5e *live non-optimized*
+- nvme6 *fc* traddr=nn-0x208100a098dfdd91:pn- 0x208300a098dfdd91,host_traddr=nn-0x200000109b579d5f:pn-0x100000109b579d5f *live non-optimized*
----
--
.NVMe/TCP
--
* 예제 출력 *

[listing, subs="+quotes"]
----
# nvme list-subsys
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_dhchap
hostnqn=nqn.2014-08.org.nvmexpress:uuid:e58eca24-faff-11ea-8fee-3a68dd3b5c5f
iopolicy=round-robin

 +- nvme0 *tcp* traddr=192.168.2.214,trsvcid=4420,host_traddr=192.168.2.14 *live*
 +- nvme1 *tcp* traddr=192.168.2.215,trsvcid=4420,host_traddr=192.168.2.14 *live*
 +- nvme2 *tcp* traddr=192.168.1.214,trsvcid=4420,host_traddr=192.168.1.14 *live*
 +- nvme3 *tcp* traddr=192.168.1.215,trsvcid=4420,host_traddr=192.168.1.14 *live*
----
--
====
. NetApp 플러그인에 각 ONTAP 네임스페이스 장치에 대한 올바른 값이 표시되는지 확인합니다.
+
[role="tabbed-block"]
====
.열
--
`nvme netapp ontapdevices -o column`

* 출력 예 *:

[listing]
----

Device           Vserver                   Namespace Path                               NSID UUID                                   Size
---------------- ------------------------- -----------------------------------------------------------------------------------------------
/dev/nvme0n1     vs_CLIENT114              /vol/CLIENT114_vol_0_10/CLIENT114_ns10       1    c6586535-da8a-40fa-8c20-759ea0d69d33   1.07GB

----
--
.JSON을 참조하십시오
--
`nvme netapp ontapdevices -o json`

* 출력 예 *:

[listing]
----
{
"ONTAPdevices":[
{
"Device":"/dev/nvme0n1",
"Vserver":"vs_CLIENT114",
"Namespace_Path":"/vol/CLIENT114_vol_0_10/CLIENT114_ns10",
"NSID":1,
"UUID":"c6586535-da8a-40fa-8c20-759ea0d69d33",
"Size":"1.07GB",
"LBA_Data_Size":4096,
"Namespace_Size":262144
}
]
}

----
--
====




== 영구 검색 컨트롤러를 만듭니다

ONTAP 9.11.1부터 다음 절차를 사용하여 SLES 15 SP5 호스트에 대한 영구 검색 컨트롤러(PDC)를 만들 수 있습니다. PDC는 NVMe 하위 시스템의 추가 또는 제거 시나리오와 검색 로그 페이지 데이터의 변경 사항을 자동으로 감지하기 위해 필요합니다.

.단계
. 검색 로그 페이지 데이터를 사용할 수 있고 이니시에이터 포트와 타겟 LIF 조합을 통해 검색할 수 있는지 확인합니다.
+
[listing]
----
nvme discover -t <trtype> -w <host-traddr> -a <traddr>
----
+
.예제 출력:
[%collapsible]
====
[listing, subs="+quotes"]
----
Discovery Log Number of Records 16, Generation counter 14
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  0
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:discovery
traddr:  192.168.1.214
eflags:  *explicit discovery connections, duplicate discovery information sectype: none*
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  0
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:discovery
traddr:  192.168.1.215
eflags:  *explicit discovery connections, duplicate discovery information
sectype: none*
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  0
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:discovery
traddr:  192.168.2.215
eflags:  *explicit discovery connections, duplicate discovery information sectype: none*
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  0
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:discovery
traddr:  192.168.2.214
eflags:  *explicit discovery connections, duplicate discovery information sectype: none*
=====Discovery Log Entry 4======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_none
traddr:  192.168.1.214
eflags:  none
sectype: none
=====Discovery Log Entry 5======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_none
traddr:  192.168.1.215
eflags:  none
sectype: none
=====Discovery Log Entry 6======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_none
traddr:  192.168.2.215
eflags:  none
sectype: none
=====Discovery Log Entry 7======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_none
traddr:  192.168.2.214
eflags:  none
sectype: none
=====Discovery Log Entry 8======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.subsys_CLIENT114
traddr:  192.168.1.214
eflags:  none
sectype: none
=====Discovery Log Entry 9======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.subsys_CLIENT114
traddr:  192.168.1.215
eflags:  none
sectype: none
=====Discovery Log Entry 10======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.subsys_CLIENT114
traddr:  192.168.2.215
eflags:  none
sectype: none
=====Discovery Log Entry 11======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.subsys_CLIENT114
traddr:  192.168.2.214
eflags:  none
sectype: none
=====Discovery Log Entry 12======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_dhchap
traddr:  192.168.1.214
eflags:  none
sectype: none
=====Discovery Log Entry 13======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_dhchap
traddr:  192.168.1.215
eflags:  none
sectype: none
=====Discovery Log Entry 14======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_dhchap
traddr:  192.168.2.215
eflags:  none
sectype: none
=====Discovery Log Entry 15======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  0
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.0501daf15dda11eeab68d039eaa7a232:subsystem.unidir_dhchap
traddr:  192.168.2.214
eflags:  none
sectype: none
----
====
. 검색 하위 시스템에 대한 PDC 생성:
+
[listing]
----
nvme discover -t <trtype> -w <host-traddr> -a <traddr> -p
----
+
* 출력 예: *

+
[listing]
----
nvme discover -t tcp -w 192.168.1.16 -a 192.168.1.116 -p
----
. ONTAP 컨트롤러에서 PDC가 생성되었는지 확인합니다.
+
[listing]
----
vserver nvme show-discovery-controller -instance -vserver vserver_name
----
+
* 출력 예: *

+
[listing, subs="+quotes"]
----
vserver nvme show-discovery-controller -instance -vserver vs_nvme175
Vserver Name: vs_CLIENT116 Controller ID: 00C0h
Discovery Subsystem NQN: *nqn.1992- 08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:discovery* Logical Interface UUID: d23cbb0a-c0a6-11ec-9731-d039ea165abc Logical Interface: CLIENT116_lif_4a_1
Node: A400-14-124
Host NQN: nqn.2014-08.org.nvmexpress:uuid:12372496-59c4-4d1b-be09- 74362c0c1afc
Transport Protocol: nvme-tcp
Initiator Transport Address: 192.168.1.16
Host Identifier: 59de25be738348f08a79df4bce9573f3 Admin Queue Depth: 32
Header Digest Enabled: false Data Digest Enabled: false
Vserver UUID: 48391d66-c0a6-11ec-aaa5-d039ea165514
----




== 보안 대역내 인증을 설정합니다

ONTAP 9.12.1부터 SLES 15 SP5 호스트와 ONTAP 컨트롤러 간에 NVMe/TCP 및 NVMe/FC를 통해 보안 인밴드 인증이 지원됩니다.

보안 인증을 설정하려면 각 호스트 또는 컨트롤러가 에 연결되어 있어야 합니다 `DH-HMAC-CHAP` 키 - NVMe 호스트 또는 컨트롤러의 NQN과 관리자가 구성한 인증 비밀의 조합입니다. 피어를 인증하려면 NVMe 호스트 또는 컨트롤러가 피어와 연결된 키를 인식해야 합니다.

CLI 또는 구성 JSON 파일을 사용하여 보안 대역 내 인증을 설정할 수 있습니다. 서로 다른 하위 시스템에 대해 다른 dhchap 키를 지정해야 하는 경우 구성 JSON 파일을 사용해야 합니다.

[role="tabbed-block"]
====
.CLI를 참조하십시오
--
.단계
. 호스트 NQN 가져오기:
+
[listing]
----
cat /etc/nvme/hostnqn
----
. SLES15 SP5 호스트에 대한 dhchap 키를 생성합니다.
+
[listing]
----
nvme gen-dhchap-key -s optional_secret -l key_length {32|48|64} -m HMAC_function {0|1|2|3} -n host_nqn

•	-s secret key in hexadecimal characters to be used to initialize the host key
•	-l length of the resulting key in bytes
•	-m HMAC function to use for key transformation
0 = none, 1- SHA-256, 2 = SHA-384, 3=SHA-512
•	-n host NQN to use for key transformation
----
+
다음 예에서는 HMAC이 3(SHA-512)으로 설정된 임의의 dhchap 키가 생성됩니다.

+
[listing]
----
# nvme gen-dhchap-key -m 3 -n nqn.2014-08.org.nvmexpress:uuid:d3ca725a- ac8d-4d88-b46a-174ac235139b
DHHC-1:03:J2UJQfj9f0pLnpF/ASDJRTyILKJRr5CougGpGdQSysPrLu6RW1fGl5VSjbeDF1n1DEh3nVBe19nQ/LxreSBeH/bx/pU=:
----
. ONTAP 컨트롤러에서 호스트를 추가하고 두 dhchap 키를 모두 지정합니다.
+
[listing]
----
vserver nvme subsystem host add -vserver <svm_name> -subsystem <subsystem> -host-nqn <host_nqn> -dhchap-host-secret <authentication_host_secret> -dhchap-controller-secret <authentication_controller_secret> -dhchap-hash-function {sha-256|sha-512} -dhchap-group {none|2048-bit|3072-bit|4096-bit|6144-bit|8192-bit}
----
. 호스트는 단방향 및 양방향이라는 두 가지 유형의 인증 방법을 지원합니다. 호스트에서 ONTAP 컨트롤러에 연결하고 선택한 인증 방법에 따라 dhchap 키를 지정합니다.
+
[listing]
----
nvme connect -t tcp -w <host-traddr> -a <tr-addr> -n <host_nqn> -S <authentication_host_secret> -C <authentication_controller_secret>
----
. 의 유효성을 검사합니다 `nvme connect authentication` 호스트 및 컨트롤러 dhchap 키를 확인하여 명령:
+
.. 호스트 dhchap 키를 확인합니다.
+
[listing]
----
$cat /sys/class/nvme-subsystem/<nvme-subsysX>/nvme*/dhchap_secret
----
+
* 단방향 설정의 예제 출력: *

+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys1/nvme*/dhchap_secret
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
DHHC-1:03:je1nQCmjJLUKD62mpYbzlpuw0OIws86NB96uNO/t3jbvhp7fjyR9bIRjOHg8wQtye1JCFSMkBQH3pTKGdYR1OV9gx00=:
----
.. 컨트롤러 dhchap 키를 확인합니다.
+
[listing]
----
$cat /sys/class/nvme-subsystem/<nvme-subsysX>/nvme*/dhchap_ctrl_secret
----
+
* 양방향 구성의 출력 예: *

+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys6/nvme*/dhchap_ctrl_secret
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:
DHHC-1:03:WorVEV83eYO53kV4Iel5OpphbX5LAphO3F8fgH3913tlrkSGDBJTt3crXeTUB8fCwGbPsEyz6CXxdQJi6kbn4IzmkFU=:
----




--
.JSON 파일
--
를 사용할 수 있습니다 `/etc/nvme/config.json` 파일이 있는 파일 `nvme connect-all` ONTAP 컨트롤러 구성에서 여러 NVMe 서브시스템을 사용할 수 있는 경우에 명령을 사용합니다.

을 사용하여 JSON 파일을 생성할 수 있습니다 `-o` 옵션을 선택합니다. 자세한 구문 옵션은 NVMe connect-all man 페이지를 참조하십시오.

.단계
. JSON 파일 구성:
+
[listing]
----
# cat /etc/nvme/config.json
[
 {
    "hostnqn":"nqn.2014-08.org.nvmexpress:uuid:12372496-59c4-4d1b-be09-74362c0c1afc",
    "hostid":"3ae10b42-21af-48ce-a40b-cfb5bad81839",
    "dhchap_key":"DHHC-1:03:Cu3ZZfIz1WMlqZFnCMqpAgn/T6EVOcIFHez215U+Pow8jTgBF2UbNk3DK4wfk2EptWpna1rpwG5CndpOgxpRxh9m41w=:"
 },

 {
    "hostnqn":"nqn.2014-08.org.nvmexpress:uuid:12372496-59c4-4d1b-be09-74362c0c1afc",
    "subsystems":[
        {
            "nqn":"nqn.1992-08.com.netapp:sn.48391d66c0a611ecaaa5d039ea165514:subsystem.subsys_CLIENT116",
            "ports":[
               {
                    "transport":"tcp",
                    "traddr":"192.168.1.117",
                    "host_traddr":"192.168.1.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               },
               {
                    "transport":"tcp",
                    "traddr":"192.168.1.116",
                    "host_traddr":"192.168.1.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               },
               {
                    "transport":"tcp",
                    "traddr":"192.168.2.117",
                    "host_traddr":"192.168.2.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               },
               {
                    "transport":"tcp",
                    "traddr":"192.168.2.116",
                    "host_traddr":"192.168.2.16",
                    "trsvcid":"4420",
                    "dhchap_ctrl_key":"DHHC-1:01:0h58bcT/uu0rCpGsDYU6ZHZvRuVqsYKuBRS0Nu0VPx5HEwaZ:"
               }
           ]
       }
   ]
 }
]

[NOTE]
In the preceding example, `dhchap_key` corresponds to `dhchap_secret` and `dhchap_ctrl_key` corresponds to `dhchap_ctrl_secret`.
----
. config JSON 파일을 사용하여 ONTAP 컨트롤러에 연결합니다.
+
[listing]
----
nvme connect-all -J /etc/nvme/config.json
----
+
* 출력 예 *:

+
[listing]
----
traddr=192.168.2.116 is already connected
traddr=192.168.1.116 is already connected
traddr=192.168.2.117 is already connected
traddr=192.168.1.117 is already connected
traddr=192.168.2.117 is already connected
traddr=192.168.1.117 is already connected
traddr=192.168.2.116 is already connected
traddr=192.168.1.116 is already connected
traddr=192.168.2.116 is already connected
traddr=192.168.1.116 is already connected
traddr=192.168.2.117 is already connected
traddr=192.168.1.117 is already connected
----
. 각 하위 시스템에 대해 해당 컨트롤러에 대해 dhchap 암호가 활성화되어 있는지 확인합니다.
+
.. 호스트 dhchap 키를 확인합니다.
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys0/nvme0/dhchap_secret
----
+
* 출력 예: *

+
[listing]
----
DHHC-1:01:NunEWY7AZlXqxITGheByarwZdQvU4ebZg9HOjIr6nOHEkxJg:
----
.. 컨트롤러 dhchap 키를 확인합니다.
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys0/nvme0/dhchap_ctrl_secret
----
+
* 출력 예: *

+
[listing]
----
DHHC-
1:03:2YJinsxa2v3+m8qqCiTnmgBZoH6mIT6G/6f0aGO8viVZB4VLNLH4z8CvK7pV YxN6S5fOAtaU3DNi12rieRMfdbg3704=:

----




--
====


== 알려진 문제

SLES 15 SP5의 ONTAP 릴리스에 대해서는 알려진 문제가 없습니다.
