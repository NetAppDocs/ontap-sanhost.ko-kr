---
sidebar: sidebar 
permalink: nvme_rhel_94.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: ONTAP가 포함된 RHEL 9.4용 NVMe-oF 호스트를 구성하는 방법 
---
= ONTAP 탑재 RHEL 9.4 에 대한 NVMe-oF 호스트 구성
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
NVMe/FC(NVMe over Fibre Channel) 및 기타 전송을 비롯한 NVMe-oF(NVMe over Fabrics)는 Red Hat Enterprise Linux(RHEL) 9.4 및 ANA(Asymmetric Namespace Access) 에서 지원됩니다. NVMe-oF 환경의 경우, ANA는 iSCSI 및 FC 환경에서 ALUA 다중 경로와 동일하며 커널 내 NVMe 다중 경로를 통해 구현됩니다.

ONTAP가 포함된 RHEL 9.4에 대한 NVMe-oF 호스트 구성에 대해 다음 지원을 사용할 수 있습니다.

* NVMe/FC 외에 NVMe over TCP(NVMe/TCP) 지원 NetApp 플러그인은 기본 제공됩니다 `nvme-cli` 패키지에는 NVMe/FC 및 NVMe/TCP 네임스페이스에 대한 ONTAP 세부 정보가 표시됩니다.
* NVMe 네임스페이스를 요청하지 않도록 명시적인 dm-multipath 설정 없이 지정된 HBA(호스트 버스 어댑터)에서 동일한 호스트에서 NVMe 및 SCSI가 공존하는 트래픽을 사용합니다.


지원되는 구성에 대한 자세한 내용은 를 참조하십시오 link:https://mysupport.netapp.com/matrix/["NetApp 상호 운용성 매트릭스 툴"^].



== 피처

* RHEL 9.4에는 기본적으로 NVMe 네임스페이스를 위해 커널 내 NVMe 다중 경로가 활성화되어 있으므로 명시적 설정이 필요하지 않습니다.
* NVMe/FC 프로토콜을 사용한 SAN 부팅이 지원됩니다.




== 알려진 제한 사항

알려진 제한은 없습니다.



== 소프트웨어 버전을 확인합니다

다음 절차에 따라 지원되는 최소 RHEL 9.4 소프트웨어 버전을 검증할 수 있습니다.

.단계
. 서버에 RHEL 9.4를 설치합니다. 설치가 완료되면 지정된 RHEL 9.4 커널을 실행하고 있는지 확인합니다.
+
[listing]
----
# uname -r
----
+
* 출력 예: *

+
[listing]
----
5.14.0-423.el9.x86_64
----
. "NVMe-CLI" 패키지를 설치합니다.
+
[listing]
----
# rpm -qa|grep nvme-cli
----
+
* 출력 예: *

+
[listing]
----
nvme-cli-2.6-4.el9.x86_64
----
. 를 설치합니다 `libnvme` 패키지:
+
[listing]
----
#rpm -qa|grep libnvme
----
+
* 예제 출력 *

+
[listing]
----
libnvme-1.6-1.el9.x86_64
----
. RHEL 9.4 호스트에서 에서 hostnqn 문자열을 확인합니다 `/etc/nvme/hostnqn`:
+
[listing]
----
# cat /etc/nvme/hostnqn
----
+
* 예제 출력 *

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid: uuid:4c4c4544-0036-5610-804a-c7c04f365a32
----
. 를 확인합니다 `hostnqn` 문자열이 과 일치합니다 `hostnqn` ONTAP 배열의 해당 하위 시스템에 대한 문자열:
+
[listing]
----
::> vserver nvme subsystem host show -vserver vs_coexistence_LPE36002
----
+
* 출력 예: *

+
[listing]
----
Vserver     Subsystem          Host NQN
----------- --------------- ----------------------------------------------------------
vs_coexistence_LPE36002   nvme    nqn.2014-08.org.nvmexpress:uuid: 4c4c4544-0036-5610-804a-
----
+

NOTE: 를 누릅니다 `hostnqn` 문자열이 일치하지 않습니다. 를 사용하십시오 `vserver modify` 명령을 사용하여 를 업데이트합니다 `hostnqn` 와 일치하는 해당 ONTAP 배열 하위 시스템의 문자열입니다 `hostnqn` 문자열 시작 `/etc/nvme/hostnqn` 호스트.





== NVMe/FC 구성

Broadcom/Emulex 또는 Marvell/Qlogic 어댑터에 대해 NVMe/FC를 구성할 수 있습니다.

[role="tabbed-block"]
====
.Broadcom/Emulex
--
.단계
. 지원되는 어댑터 모델을 사용하고 있는지 확인합니다.
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
----
+
* 출력 예: *

+
[listing]
----
LPe36002-M64
LPe36002-M64

----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
----
+
* 출력 예: *

+
[listing]
----
Emulex LightPulse LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
Emulex LightPulse LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
----
. 권장 Broadcom을 사용하고 있는지 확인합니다 `lpfc` 펌웨어 및 받은 편지함 드라이버:
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
14.2.673.40, sli-4:6:d
14.2.673.40, sli-4:6:d


# cat /sys/module/lpfc/version
0:14.2.0.16
----
+
지원되는 어댑터 드라이버 및 펌웨어 버전의 최신 목록은 를 참조하십시오 link:https://mysupport.netapp.com/matrix/["NetApp 상호 운용성 매트릭스 툴"^].

. 확인합니다 `lpfc_enable_fc4_type` 가 로 설정되어 있습니다 `3`:
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. 이니시에이터 포트가 가동 및 실행 중이며 타겟 LIF를 볼 수 있는지 확인합니다.
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b3c081f
0x100000109b3c0820

----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing, subs="+quotes"]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b3c081f WWNN x200000109b3c081f DID x062300 *ONLINE*
NVME RPORT       WWPN x2143d039ea165877 WWNN x2142d039ea165877 DID x061b15 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2145d039ea165877 WWNN x2142d039ea165877 DID x061115 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000040b Cmpl 000000040b Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000001f5c4538 Issue 000000001f58da22 OutIO fffffffffffc94ea
abort 00000630 noxri 00000000 nondlp 00001071 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000630 Err 0001bd4a
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b3c0820 WWNN x200000109b3c0820 DID x062c00 *ONLINE*
NVME RPORT       WWPN x2144d039ea165877 WWNN x2142d039ea165877 DID x060215 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2146d039ea165877 WWNN x2142d039ea165877 DID x061815 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000040b Cmpl 000000040b Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000001f5c3618 Issue 000000001f5967a4 OutIO fffffffffffd318c
abort 00000629 noxri 00000000 nondlp 0000044e qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000629 Err 0001bd3d

----


--
.NVMe/FC용 Marvell/QLogic FC 어댑터
--
.단계
. RHEL 9.4 GA 커널에 포함된 기본 받은 편지함 qla2xxx 드라이버에는 ONTAP 지원에 필요한 최신 수정 사항이 포함되어 있습니다. 지원되는 어댑터 드라이버 및 펌웨어 버전을 실행하고 있는지 확인합니다.
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
----
+
* 예제 출력 *

+
[listing]
----
QLE2872 FW:v9.12.01 DVR:v10.02.09.100-k
QLE2872 FW:v9.12.01 DVR:v10.02.09.100-k
----
. 확인합니다 `ql2xnvmeenable` 가 설정됩니다. 그러면 Marvell 어댑터가 NVMe/FC Initiator로 작동할 수 있습니다.
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== 1MB I/O 활성화(옵션)

ONTAP는 컨트롤러 식별 데이터에서 MDTS(MAX Data 전송 크기)를 8로 보고합니다. 이는 최대 I/O 요청 크기가 1MB까지 될 수 있음을 의미합니다. Broadcom NVMe/FC 호스트에 대해 1MB 크기의 I/O 요청을 발행하려면 `lpfc` `lpfc_sg_seg_cnt` 매개 변수 값을 기본값인 64에서 256으로 늘려야 합니다.

.단계
.  `lpfc_sg_seg_cnt`매개변수를 256으로 설정합니다.
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
.  `dracut -f`명령을 실행하고 호스트를 재부팅합니다.
. 가 `lpfc_sg_seg_cnt` 256인지 확인합니다.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----



NOTE: Qlogic NVMe/FC 호스트에는 적용되지 않습니다.



== NVMe/TCP를 구성합니다

NVMe/TCP에는 자동 연결 기능이 없습니다. 따라서 NVMe/TCP 하위 시스템과 네임스페이스를 검색하려면 NVMe/TCP 연결 또는 connect-all 기능을 수동으로 수행해야 합니다.

다음 절차를 사용하여 NVMe/TCP를 구성할 수 있습니다.

.단계
. 이니시에이터 포트가 지원되는 NVMe/TCP LIF에서 검색 로그 페이지 데이터를 가져올 수 있는지 확인합니다.
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
* 출력 예: *

+
[listing, subs="+quotes"]
----
# nvme discover -t tcp -w 192.168.167.1 -a 192.168.167.16

Discovery Log Number of Records 8, Generation counter 10
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  11
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.167.8
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  9
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.166.8
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  12
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.167.7
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: current discovery subsystem
treq:    not specified
portid:  10
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:
discovery
traddr:  192.168.166.7
eflags:  explicit discovery connections, duplicate discovery information
sectype: none
=====Discovery Log Entry 4======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  11
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.167.8
eflags:  none
sectype: none
=====Discovery Log Entry 5======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  9
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.166.8
eflags:  none
sectype: none
=====Discovery Log Entry 6======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  12
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.167.7
eflags:  none
sectype: none
=====Discovery Log Entry 7======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  10
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1
traddr:  192.168.166.7
eflags:  none
sectype: none
----
. 다른 NVMe/TCP 이니시에이터-타겟 LIF 조합이 검색 로그 페이지 데이터를 성공적으로 가져올 수 있는지 확인합니다.
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
* 출력 예: *

+
[listing]
----
#nvme discover -t tcp -w 192.168.166.6 -a 192.168.166.7
#nvme discover -t tcp -w 192.168.166.6 -a 192.168.166.8
#nvme discover -t tcp -w 192.168.167.6 -a 192.168.167.7
#nvme discover -t tcp -w 192.168.167.6 -a 192.168.167.8
----
. 를 실행합니다 `nvme connect-all` 노드에 걸쳐 지원되는 모든 NVMe/TCP 이니시에이터-타겟 LIF에 대한 명령:
+
[listing]
----
nvme connect-all -t tcp -w host-traddr -a traddr
----
+
* 출력 예: *

+
[listing]
----
#	nvme	connect-all	-t	tcp	-w	192.168.166.6	-a	192.168.166.7
#	nvme	connect-all	-t	tcp	-w	192.168.166.6	-a	192.168.166.8
#	nvme	connect-all	-t	tcp	-w	192.168.167.6	-a	192.168.167.7
#	nvme	connect-all	-t	tcp	-w	192.168.167.6	-a	192.168.167.8
----



NOTE: RHEL 9.4부터 NVMe/TCP의 기본 설정입니다 `ctrl_loss_tmo` 시간 초과가 해제되어 다시 시도 횟수에 제한이 없습니다(무제한 재시도). 따라서 특정 을 수동으로 구성할 필요가 없습니다 `ctrl_loss_tmo` 를 사용하는 경우 시간 초과 지속 시간 `nvme connect` 또는 `nvme connect-all` 명령(option-l). 이 기본 동작에서는 경로 장애 발생 시 NVMe/TCP 컨트롤러가 시간 초과를 경험하지 않고 무기한 연결된 상태를 유지합니다.



== NVMe-oF를 검증합니다

다음 절차를 사용하여 NVMe-oF를 검증할 수 있습니다.

.단계
. in-kernel NVMe multipath가 활성화되어 있는지 확인합니다.
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. 각 ONTAP 네임스페이스에 대한 적절한 NVMe-oF 설정(예: NetApp ONTAP 컨트롤러로 설정된 모델 및 라운드 로빈으로 설정된 로드 밸런싱 IPolicy가 호스트에 올바르게 반영되는지 확인합니다.
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. 호스트에서 네임스페이스가 생성되고 올바르게 검색되는지 확인합니다.
+
[listing]
----
# nvme list
----
+
* 출력 예: *

+
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme4n1 81Ix2BVuekWcAAAAAAAB	NetApp ONTAP Controller


Namespace Usage    Format             FW             Rev
-----------------------------------------------------------
1                 21.47 GB / 21.47 GB	4 KiB + 0 B   FFFFFFFF
----
. 각 경로의 컨트롤러 상태가 라이브이고 올바른 ANA 상태인지 확인합니다.
+
[role="tabbed-block"]
====
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme5n21
----
* 출력 예: *

[listing, subs="+quotes"]
----
nvme-subsys4 - NQN=nqn.1992-08.com.netapp:sn.efd7989cb10111ee871ed039ea954d18:subsystem.nvme
            hostnqn=nqn.2014-08.org.nvmexpress:uuid:d3b581b4-c975-11e6-8425-0894ef31a074
 iopolicy=round-robin
 \
  +- nvme2 fc traddr=nn-0x2013d039ea951c45:pn-0x2018d039ea951c45,host_traddr=nn-0x200000109bdacc76:pn-0x100000109bdacc76 live *non-optimized*
  +- nvme3 fc traddr=nn-0x2013d039ea951c45:pn-0x2017d039ea951c45,host_traddr=nn-0x200000109bdacc75:pn-0x100000109bdacc75 live *non-optimized*
  +- nvme5 fc traddr=nn-0x2013d039ea951c45:pn-0x2016d039ea951c45,host_traddr=nn-   0x200000109bdacc76:pn-0x100000109bdacc76 live *optimized*
  +- nvme6 fc traddr=nn-0x2013d039ea951c45:pn-0x2014d039ea951c45,host_traddr=nn-  0x200000109bdacc75:pn-0x100000109bdacc75 live *optimized*

----
--
.NVMe/TCP
--
[listing]
----
# nvme list-subsys /dev/nvme1n1
----
* 출력 예: *

[listing, subs="+quotes"]
----

nvme-subsys1 -NQN=nqn.1992-08.com.netapp:
sn.983de7f4b39411ee871ed039ea954d18:subsystem.nvme_tcp_1         hostnqn=nqn.2014-08.org.nvmexpress:uuid:
4c4c4544-0035-5910-804b-c2c04f444d33
iopolicy=round-robin
\
+- nvme5 tcp traddr=192.168.166.7,trsvcid=4420,host_traddr=192.168.166.6,src_addr=192.168.166.6 *live*
+- nvme4 tcp traddr=192.168.166.8,trsvcid=4420,host_traddr=192.168.166.6,src_addr=192.168.166.6 *live*
+- nvme2 tcp traddr=192.168.167.7,trsvcid=4420,host_traddr=192.168.167.6,src_addr=192.168.167.6 *live*
+- nvme1 tcp traddr=192.168.167.8,trsvcid=4420,host_traddr=192.168.167.6,src_addr=192.168.167.6 *live*

----
--
====
. NetApp 플러그인에 각 ONTAP 네임스페이스 장치에 대한 올바른 값이 표시되는지 확인합니다.
+
[role="tabbed-block"]
====
.열
--
[listing]
----
# nvme netapp ontapdevices -o column
----
* 출력 예: *

[listing]
----
Device        Vserver   Namespace Path
----------------------- ------------------------------
/dev/nvme0n1 vs_tcp           /vol/vol1/ns1



NSID       UUID                                   Size
------------------------------------------------------------
1          6fcb8ea0-dc1e-4933-b798-8a62a626cb7f	21.47GB
----
--
.JSON을 참조하십시오
--
[listing]
----
# nvme netapp ontapdevices -o json
----
* 예제 출력 *

[listing]
----
{

"ONTAPdevices" : [
{

"Device" : "/dev/nvme1n1", "Vserver" : "linux_tcnvme_iscsi", "Namespace_Path" : "/vol/tcpnvme_1_0_0/tcpnvme_ns", "NSID" : 1,
"UUID" : "1a42c652-1450-4a29-886a-b4ccc23e637d", "Size" : "21.47GB",
"LBA_Data_Size" : 4096,
"Namespace_Size" : 5242880
},

]
}


----
--
====




== 알려진 문제

ONTAP 릴리즈가 포함된 RHEL 9.4의 NVMe-oF 호스트 구성에는 알려진 문제가 없습니다.
